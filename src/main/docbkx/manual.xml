<?xml version="1.0" encoding="UTF-8"?>
<?xml-model href="http://www.oasis-open.org/docbook/xml/5.0/rng/docbook.rng" schematypens="http://relaxng.org/ns/structure/1.0"?>
<book xmlns="http://docbook.org/ns/docbook" xmlns:xlink="http://www.w3.org/1999/xlink" version="5.0">
    <info>
        <title>KAJUKodules</title>
        <subtitle>User's Guide</subtitle>
        <author>
            <personname>
                <firstname>Martin</firstname>
                <surname>Homuth</surname>
            </personname>
            <email>martin.homuth@staff.hu-berlin.de</email>
        </author>
        <author>
            <orgname xml:id="snp_org3"> Technische Universität Berlin </orgname>
        </author>
        <copyright>
            <year>2013</year>
            <holder> INRIA, SFB 632 Information Structure / D1 Linguistic Database,
                Humboldt-Universität zu Berlin, Universität Potsdam, All rights reserved. </holder>
        </copyright>
        <releaseinfo>Version ${project.version}</releaseinfo>
    </info>
    <preface>
        <title>Foreword</title>
        <para>The intention of this document is first to give a guide to the user of how to use the
            here mentioned pepper modules and how to utilize a mapping performed by them. Second
            this document shall give a closer view in the details of such a mapping in a declarative
            way, to give the user a chance to understand how specific data will be mapped by the
            presented pepper modules.</para>
    </preface>
    <chapter>
        <title>Overview</title>
        <para>This project contains an importer for the Kasseler Junktionskorpus, see
                http://www.uni-giessen.de/kajuk/. 
        </para>
        <para>The import of the corpus utilizes a mapping to Salt with the use of a SAX-parser. The
            mapping itself includes the conversion from the corpus annotations to a ANNIS-usable
            token-based setting.</para>
        
                
        
        
        
        
    </chapter>
    <chapter>
        <title>Corpus Properties</title>
        <para>The KAJUK corpus is segmented into phrases or between conjunctions, thus the text
                is tokenized using the Salt implementation of the TreeTagger tokenizer. </para>
        <para>The annotations are realized in nested xml tags, which are not adoptable to Salt [OR
            ANNIS??], hence a key-value representation of those elements is necessary.</para>
        <section>
            <title>Graphical line and page breaks</title>
        
            <para>In the corpus for line breaks an inconsistent method was used, as can be seen in <link
                xlink:href="https://korpling.german.hu-berlin.de/p/boards/7/topics/59">here</link>.
            This inconsistency required the introduction of new elements to prevent changing the
            structure of the corpus. The original <emphasis>line</emphasis>- and
                <emphasis>pb</emphasis>-elements are ignored during the parsing process as well as
            the comments, which are (sometimes) used for the line breaks, and replaced with
                <emphasis>newline</emphasis>- and <emphasis>newpage</emphasis>-elements, also as
            shown below. These inserted elements </para>
            <para><inlinemediaobject>
                    <imageobject>
                        <imagedata fileref="images/annotationExample.png"/>
                    </imageobject>
                </inlinemediaobject></para>
        </section>
        <section>
            <title>Ellipsis</title>
            <para>An example for an ellipsis can be seen in the following example.
                <inlinemediaobject>
                    <imageobject>
                        <imagedata fileref="images/ellipsisExample.png"/>
                    </imageobject>
                </inlinemediaobject></para>
            <para>The ellipsis of the corpus are identified by specific attributes of elements and
                as a result, because of the decision of keeping the elliptic text in the main text,
                the token annotations receive. </para>
        </section>
    </chapter>
    <chapter>
        <title>Module Usage</title>
        <para>Because the importer is implemented in a static way, there are no customization
            options. Every document of the corpus will be parsed and mapped to Salt. Then the
            created Salt representation can be used for further processing.</para>
    </chapter>
    <chapter>
        <title>Implementation Details</title>
        <para>
            This chapter covers the details of the importer implementation to create the Salt
                mapping for exporting the corpus to the RelANNIS format.
        </para>
        <section>
            <title>The characters() method</title>
            <para>In the characters() method, the parsed characters array is appended to the
                STextualDS of the DocumentGraph while the involved part is tokenized with the Salt
                implementation of the TreeTagger. The created STokens are then added to the SLayers
                for the different categories, e.g. <emphasis>junktionen</emphasis> or
                    <emphasis>lexikalische_annotationen</emphasis>. <note>
                    <para>These layers weren't used in the laudatio project, the actual RelANNIS
                        files were configured by hand, so the Salt equivalent for the RelANNIS
                        exporter is not implemented yet.</para>
                </note> Those layers are used for grouping in the ANNIS webinterface. In the end,
                every SToken's reference is saved for every element opened to create a SSpan later
                on.</para>
            <para>Additionally, modifications for elliptic annotations are done here.</para>
        </section>
        <section>
            <title>The startElement() method</title>
            <para>When a new element is openend, several things are done:<orderedlist>
                    <listitem>
                        <para>Skipping <emphasis>pb</emphasis>- and
                            <emphasis>line</emphasis>-elements completely</para>
                    </listitem>
                    <listitem>
                        <para>Determine multi-level <emphasis>lb</emphasis>-elements, see
                            [REFERENCE]</para>
                    </listitem>
                    <listitem>
                        <para>Creating SSpans for <emphasis>newline</emphasis>- and
                                <emphasis>newpage</emphasis>-elements</para>
                    </listitem>
                    <listitem>
                        <para>The key-value pair(s) for the opened element and it's attributes is
                            created, see [REFERENCE TO CONVERSION]. The conversion class created for
                            this purpose simply defines the SAnnotation accordingly</para>
                    </listitem>
                    <listitem>
                        <para>The information about the opened element is saved</para>
                    </listitem>
                </orderedlist></para>
        </section>
        <section>
            <title>The endElement() method</title>
            <para>As with the <emphasis>startElement()</emphasis> there are several things to do here:<orderedlist>
                    <listitem>
                        <para>Skipping <emphasis>pb</emphasis>- and
                            <emphasis>line</emphasis>-elements completely</para>
                    </listitem>
                    <listitem>
                        <para>If the element is a <emphasis>newline</emphasis>- or
                                <emphasis>newpage</emphasis>-element, the information is
                            saved</para>
                    </listitem>
                    <listitem>
                        <para>A SSpan for each saved STokens within this element is created as well
                            as it's annotation</para>
                    </listitem>
                    <listitem>
                        <para>For every house number the closed element may contain, a SSpan is
                            created and saved for later use, see [REFERENCE TO HOUSE NUMBERS]</para>
                    </listitem>
                    <listitem>
                        <para>The STokens and SSpans created are connected with
                            SSpanningRelations</para>
                    </listitem>
                </orderedlist></para>
        </section>
        <section>
            <title>The endDocument() method</title>
            <para>When the document is parsed, the importer connects the SSpans of the same house
                number with each other with the use of SSpanningRelations. This connection happens
                in a FIFO fashion, so each SSpan points to the next occurance of the same house
                number and so on. Additionally hypotaxis and parataxis are marked with the letters
                    <emphasis>a</emphasis> and <emphasis>b</emphasis> in the house number. In this
                case the last occurance of a house number (main sentence) points to every occurance
                of the house number with the addition.</para>
        </section>
        <section>
            <title>Missing features</title>
            <para>There are some things, that are not covered by the importer module, but had to be
                manipulated by hand for the Laudation integration:<orderedlist>
                    <listitem>
                        <para>The metadata of the documents is not part of the importer itself,
                            instead there is a separate file with the information</para>
                    </listitem>
                    <listitem>
                        <para>The grouping in ANNIS is not done with the created SLayers, but by
                            hand. </para>
                    </listitem>
                </orderedlist></para>
        </section>
    </chapter>
    <chapter>
        <title>Conversion</title>
        <para>The conversion of the annotation elements in the corpus to the key-value pairs can be
            found <link xlink:href="https://korpling.german.hu-berlin.de/p/documents/145"
                >here</link>. </para>
    </chapter>
</book>
